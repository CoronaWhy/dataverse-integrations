{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation is mostly taken from https://github.com/AUSSDA/pyDataverse_demo_tromso/blob/master/pydataverse.ipynb\n",
    "\n",
    "Atuhor: Matthieu Pons (pons.matthieu@gmail.com or https://github.com/mpons for support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Python modules\n",
    "import json\n",
    "import os\n",
    "import subprocess as sp\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from pyDataverse.api import Api\n",
    "from pyDataverse.models import Datafile, Dataset\n",
    "from pyDataverse.utils import read_csv_to_dict\n",
    "from pyDataverse.utils import read_file\n",
    "\n",
    "from config import LOCAL_RESSOURCES_FOLDER, DV_ALIAS, BASE_URL, API_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataverse dataverse-s3 https://dataverse.s3.coronawhy.org a93f3909-c481-46d2-9f06-38663a2c9d05\n"
     ]
    }
   ],
   "source": [
    "print(LOCAL_RESSOURCES_FOLDER, DV_ALIAS, BASE_URL, API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset_keys(dataset_row, data, terms_filename):\n",
    "    if pd.isnull(dataset_row['organization.dataset_id']):\n",
    "        return data\n",
    "    \n",
    "    ds_tmp = {}\n",
    "    ds_id = dataset_row['organization.dataset_id']\n",
    "    ds_tmp['termsOfAccess'] = read_file(terms_filename)\n",
    "    \n",
    "    if not pd.isnull(dataset_row['dataverse.title']):\n",
    "        ds_tmp['title'] = dataset_row['dataverse.title']\n",
    "    \n",
    "    if not pd.isnull(dataset_row['dataverse.subtitle']):\n",
    "        ds_tmp['subtitle'] = dataset_row['dataverse.subtitle']\n",
    "    \n",
    "    if not pd.isnull(dataset_row['dataverse.author']):\n",
    "        ds_tmp['author'] = json.loads(dataset_row['dataverse.author'])\n",
    "    \n",
    "    if not pd.isnull(dataset_row['dataverse.dsDescription']):\n",
    "        ds_tmp['dsDescription'] = [{'dsDescriptionValue': dataset_row['dataverse.dsDescription']}]\n",
    "    \n",
    "    if not pd.isnull(dataset_row['dataverse.keywordValue']):\n",
    "        ds_tmp['keyword'] = json.loads(dataset_row['dataverse.keywordValue'])\n",
    "    \n",
    "    if not pd.isnull(dataset_row['dataverse.topicClassification']):\n",
    "        ds_tmp['topicClassification'] = json.loads(dataset_row['dataverse.topicClassification'])\n",
    "    \n",
    "    if not pd.isnull(dataset_row['dataverse.language']):\n",
    "        ds_tmp['language'] = json.loads(dataset_row['dataverse.language'])\n",
    "    \n",
    "    if not pd.isnull(dataset_row['dataverse.subject']):\n",
    "        ds_tmp['subject'] = [dataset_row['dataverse.subject']]\n",
    "    \n",
    "    if not pd.isnull(dataset_row['dataverse.kindOfData']):\n",
    "        ds_tmp['kindOfData'] = json.loads(dataset_row['dataverse.kindOfData'])\n",
    "    \n",
    "    if not pd.isnull(dataset_row['dataverse.datasetContact']):\n",
    "        ds_tmp['datasetContact'] = json.loads(dataset_row['dataverse.datasetContact'])\n",
    "    \n",
    "    data[ds_id] = {'metadata': ds_tmp}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_datafile(datafile_row, data):\n",
    "    df_tmp = {}\n",
    "    df_id = None\n",
    "    ds_id = None\n",
    "    if not pd.isnull(datafile_row['dataverse.description']):\n",
    "        df_tmp['description'] = datafile_row['dataverse.description']\n",
    "        \n",
    "    if not pd.isnull(datafile_row['organization.filename']):\n",
    "        df_tmp['filename'] = datafile_row['organization.filename']\n",
    "    if not pd.isnull(datafile_row['organization.datafile_id']):\n",
    "        df_tmp['datafile_id'] = datafile_row['organization.datafile_id']\n",
    "        df_id = datafile_row['organization.datafile_id']\n",
    "    if not pd.isnull(datafile_row['organization.dataset_id']):\n",
    "        ds_id = datafile_row['organization.dataset_id']\n",
    "        df_tmp['dataset_id'] = ds_id\n",
    "    if not pd.isnull(datafile_row['dataverse.categories']):\n",
    "        df_tmp['categories'] = json.loads(datafile_row['dataverse.categories'])\n",
    "        \n",
    "    if 'datafiles' not in data[ds_id]:\n",
    "        data[ds_id]['datafiles'] = {}\n",
    "    if df_id not in data[ds_id]['datafiles']:\n",
    "        data[ds_id]['datafiles'][df_id] = {}\n",
    "    if 'metadata' not in data[ds_id]['datafiles'][df_id]:\n",
    "        data[ds_id]['datafiles'][df_id]['metadata'] = {}\n",
    "    data[ds_id]['datafiles'][df_id]['metadata'] = df_tmp\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(api, ds, dv_alias, mapping_dsid2pid, ds_id, base_url):\n",
    "    try:\n",
    "        resp = api.create_dataset(dv_alias, ds.json())\n",
    "        pid = resp.json()['data']['persistentId']\n",
    "    except:\n",
    "        print(resp.content)\n",
    "        return resp, mapping_dsid2pid\n",
    "    \n",
    "    mapping_dsid2pid[ds_id] = pid\n",
    "    time.sleep(1)\n",
    "    print('{0}/dataset.xhtml?persistentId={1}&version=DRAFT'.format(base_url,\n",
    "                                                                    pid))\n",
    "    return resp, mapping_dsid2pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_datafile(api, pid, filename, df):\n",
    "    path = api.base_url\n",
    "    path += '/datasets/:persistentId/add?persistentId={0}'.format(pid)\n",
    "    shell_command = 'curl -H \"X-Dataverse-key: {0}\"'.format(api.api_token)\n",
    "    shell_command += ' -X POST {0} -F file=@{1}'.format(path, filename)\n",
    "    shell_command += \" -F 'jsonData={0}'\".format(df.json())\n",
    "    result = sp.run(shell_command, shell=True, stdout=sp.PIPE)\n",
    "    if filename[-4:] == '.sav' or filename[-4:] == '.dta':\n",
    "        time.sleep(20)\n",
    "    else:\n",
    "        time.sleep(2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_dataset(pid, api):\n",
    "    resp = api.delete_dataset(pid)\n",
    "    time.sleep(1)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_dataset(pid, api):\n",
    "    resp = api.publish_dataset(pid, 'major')\n",
    "    print(resp.json())\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_filename = os.path.join(LOCAL_RESSOURCES_FOLDER, 'datasets.csv')\n",
    "license_filename = os.path.join(LOCAL_RESSOURCES_FOLDER, 'license.html')\n",
    "terms_filename = os.path.join(LOCAL_RESSOURCES_FOLDER, 'terms-of-access.html')\n",
    "\n",
    "data = {}\n",
    "license_default = read_file(license_filename)\n",
    "datasets_csv = read_csv_to_dict(ds_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Datasets metadata from CSV file and save it in a dictionary\n",
    "datasets_df = pd.read_csv(ds_filename)\n",
    "data = {}\n",
    "for dataset_row in datasets_df.iterrows():\n",
    "    data = parse_dataset_keys(dataset_row[1], data, terms_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dataverse.s3.coronawhy.org a93f3909-c481-46d2-9f06-38663a2c9d05\n"
     ]
    }
   ],
   "source": [
    "print(BASE_URL, API_TOKEN)\n",
    "DV_ALIAS=\"Anton\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_api = Api(BASE_URL, API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key language not valid.\n",
      "b'{}'\n",
      "Key language not valid.\n",
      "b'{}'\n"
     ]
    }
   ],
   "source": [
    "mapping_dsid2pid = {}\n",
    "\n",
    "for ds_id, dataset in data.items():\n",
    "    ds = Dataset()\n",
    "    ds.set(dataset['metadata'])\n",
    "    \n",
    "    ds.displayName=dataset['metadata']['title']\n",
    "    \n",
    "    resp, mapping_dsid2pid = create_dataset(native_api, ds, DV_ALIAS, mapping_dsid2pid, ds_id, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [500]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filename = os.path.join(LOCAL_RESSOURCES_FOLDER, 'datafiles.csv')\n",
    "datafiles_df = pd.read_csv(df_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datafile_row in datafiles_df.iterrows():\n",
    "    data = import_datafile(datafile_row[1], data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_1': {'metadata': {'termsOfAccess': 'By accessing the file you agree to the AUSSDA <a href=\"https://aussda.at/en/terms-of-service/\">Terms of Service</a> and <a href=\"https://aussda.at/en/privacy-policy/\">Privacy Policy</a>.',\n",
       "   'title': 'Internet usage 2019',\n",
       "   'subtitle': 'How Austrians use the internet in 2019.',\n",
       "   'author': [{'authorName': 'Doe, John',\n",
       "     'authorAffiliation': 'University of Vienna'}],\n",
       "   'dsDescription': [{'dsDescriptionValue': 'Life Style 2019. Internet usage / media.'}],\n",
       "   'keyword': [{'keywordValue': 'Mass media use',\n",
       "     'keywordVocabulary': 'ELSST - The European Language Social Science Thesaurus',\n",
       "     'keywordVocabularyURI': 'https://elsst.ukdataservice.ac.uk/'}],\n",
       "   'topicClassification': [{'topicClassValue': 'Information society',\n",
       "     'topicClassVocab': 'CESSDA Topic Classification'}],\n",
       "   'language': ['German'],\n",
       "   'subject': ['Social Sciences'],\n",
       "   'kindOfData': ['numeric'],\n",
       "   'datasetContact': [{'datasetContactName': 'AUSSDA – The Austrian Social Science Data Archive',\n",
       "     'datasetContactEmail': 'info@aussda.at'}]},\n",
       "  'datafiles': {1: {'metadata': {'description': 'Core data file – 5 Variables, 20 Observations ',\n",
       "     'filename': '20001_ta_de_v1_0.tsv',\n",
       "     'datafile_id': 1,\n",
       "     'dataset_id': 'test_1',\n",
       "     'categories': ['Data']}},\n",
       "   2: {'metadata': {'description': 'Documentation: Method report and Codebook ',\n",
       "     'filename': '20001_do_de_v1_0.pdf',\n",
       "     'datafile_id': 2,\n",
       "     'dataset_id': 'test_1',\n",
       "     'categories': ['Documentation']}}}},\n",
       " 'test_2': {'metadata': {'termsOfAccess': 'By accessing the file you agree to the AUSSDA <a href=\"https://aussda.at/en/terms-of-service/\">Terms of Service</a> and <a href=\"https://aussda.at/en/privacy-policy/\">Privacy Policy</a>.',\n",
       "   'title': 'Attitute of youth towards school and profession 2018',\n",
       "   'subtitle': 'How Austrian teenagers see school and professional time',\n",
       "   'author': [{'authorName': 'Doe, Jane',\n",
       "     'authorAffiliation': 'University of Vienna'}],\n",
       "   'dsDescription': [{'dsDescriptionValue': 'Attitudes of teenagers about school and job.'}],\n",
       "   'keyword': [{'keywordValue': 'Youth',\n",
       "     'keywordVocabulary': 'ELSST - The European Language Social Science Thesaurus',\n",
       "     'keywordVocabularyURI': 'https://elsst.ukdataservice.ac.uk/'},\n",
       "    {'keywordValue': 'Youth',\n",
       "     'keywordVocabulary': 'VALUE',\n",
       "     'keywordVocabularyURI': 'https://elsst.ukdataservice.ac.uk/'},\n",
       "    {'keywordValue': 'Youth',\n",
       "     'keywordVocabulary': 'ELSST - The European Language Social Science Thesaurus',\n",
       "     'keywordVocabularyURI': 'https://elsst.ukdataservice.ac.uk/'}],\n",
       "   'topicClassification': [{'topicClassValue': 'Youth',\n",
       "     'topicClassVocab': 'CESSDA Topic Classification'},\n",
       "    {'topicClassValue': 'Education',\n",
       "     'topicClassVocab': 'CESSDA Topic Classification'},\n",
       "    {'topicClassValue': 'Employment',\n",
       "     'topicClassVocab': 'CESSDA Topic Classification'}],\n",
       "   'language': ['German'],\n",
       "   'subject': ['Social Sciences'],\n",
       "   'kindOfData': ['numeric'],\n",
       "   'datasetContact': [{'datasetContactName': 'AUSSDA – The Austrian Social Science Data Archive',\n",
       "     'datasetContactEmail': 'info@aussda.at'}]},\n",
       "  'datafiles': {3: {'metadata': {'description': 'Core data file – 6 Variables, 22 Observations ',\n",
       "     'filename': '20002_ta_de_v1_0.csv',\n",
       "     'datafile_id': 3,\n",
       "     'dataset_id': 'test_2',\n",
       "     'categories': ['Data']}},\n",
       "   4: {'metadata': {'description': 'Documentation: Method report and Codebook ',\n",
       "     'filename': '20002_do_de_v1_0.pdf',\n",
       "     'datafile_id': 4,\n",
       "     'dataset_id': 'test_2',\n",
       "     'categories': ['Documentation']}}}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-cce11a467b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping_dsid2pid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatafile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datafiles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test_1'"
     ]
    }
   ],
   "source": [
    "# upload Datafile metadata and data via API\n",
    "\n",
    "for ds_id, dataset in data.items():\n",
    "    pid = mapping_dsid2pid[ds_id]\n",
    "    for df_id, datafile in dataset['datafiles'].items():\n",
    "        data_tmp = datafile['metadata']\n",
    "        data_tmp['pid'] = pid\n",
    "        df = Datafile()\n",
    "        df.set(data_tmp)\n",
    "        filename = os.path.abspath(os.path.join('dataverse', 'files', datafile['metadata']['filename']))\n",
    "        resp = upload_datafile(native_api, pid, filename, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the Datasets at the End (OPTIONAL)\n",
    "DELETE_DATASETS = DV_ALIAS == 'demo'\n",
    "\n",
    "if DELETE_DATASETS:\n",
    "    for ds_id, dataset in data.items():\n",
    "        resp = delete_dataset(mapping_dsid2pid[ds_id], native_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
